{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Linear Regression from Scratch using Pytorch"
      ],
      "metadata": {
        "id": "QzEXft4iIACf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B0p6iIQK-ZkI"
      },
      "outputs": [],
      "source": [
        "import torch \n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs_np = np.array([[122, 267, 143], \n",
        "                   [191, 88, 64], \n",
        "                   [287, 134, 158], \n",
        "                   [102, 243, 37], \n",
        "                   [659, 96, 70]], dtype='float32')\n",
        "\n",
        "targets_np = np.array([[256, 710], \n",
        "                    [81, 101], \n",
        "                    [119, 133], \n",
        "                    [222, 137], \n",
        "                    [103, 119]], dtype='float32')"
      ],
      "metadata": {
        "id": "C_mkp_yt_Q87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = torch.from_numpy(inputs_np)\n",
        "targets = torch.from_numpy(targets_np)"
      ],
      "metadata": {
        "id": "wQz_4n0q_gg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Initializing weights and biases\n",
        "o/p_1 = w1 x para1 + w2 x para2 + w3 x para3 + b1(bias) \n",
        "o/p_2 = w4 x para1 + w5 x para2 + w6 x para3 + b2(bias)'''\n",
        "\n",
        "w = torch.randn(2, 3, requires_grad = True) # 2 output targets, 3 input parameters, hence size is 2x3. \n",
        "b = torch.randn(2, requires_grad = True)\n"
      ],
      "metadata": {
        "id": "uNpwvJoa_xPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Defining the model\n",
        "def model(x):\n",
        "  return x @ w.t() + b ############ y = x.w_transpose + b, in pytorch dot product is given by @ while the transpose is given by .t()\n",
        "\n",
        "predictions = model(inputs)\n",
        "\n",
        "\n",
        "### Defining loss function\n",
        "#### Mean Square Error loss, MSE = summation of (y_pred - y_true)^2/(n), where n is the number of elements in y_pred or y_true \n",
        "def loss_fn(t1, t2):\n",
        "  diff = t1 - t2\n",
        "  return torch.sum(diff*diff)/diff.numel()\n",
        "\n",
        "mse_loss = loss_fn(predictions, targets)\n",
        "print(targets)\n",
        "print(predictions)\n",
        "print(mse_loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvqZ_vKfBOeL",
        "outputId": "04b88de1-7621-4439-ef92-70676da8f7d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[256., 710.],\n",
            "        [ 81., 101.],\n",
            "        [119., 133.],\n",
            "        [222., 137.],\n",
            "        [103., 119.]])\n",
            "tensor([[ 137.3056,   86.4574],\n",
            "        [ 102.1952, -115.6207],\n",
            "        [ 180.4597, -220.4606],\n",
            "        [  82.0060,  160.4643],\n",
            "        [ 260.7285, -515.2204]], grad_fn=<AddBackward0>)\n",
            "tensor(102624.1875, grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Perform gradient descent for 100 epochs\n",
        "\n",
        "num_epochs = 10000\n",
        "for i in range(num_epochs):\n",
        "  preds = model(inputs)\n",
        "  loss = loss_fn(preds, targets)\n",
        "  loss.backward()\n",
        "  \n",
        "  with torch.no_grad(): # using torch.no_grad() to make sure that arithmetic operations below don't have impact on gardient\n",
        "    w-=w.grad*1e-5 # Learning rate of 1e-5\n",
        "    b-=b.grad*1e-5 \n",
        "    w.grad.zero_() # Zeroing the gradients so that their is no addition of previous gradients to the current gradient value\n",
        "    b.grad.zero_()\n"
      ],
      "metadata": {
        "id": "-xapz8l8B2Pe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Check the loss on the trained model\n",
        "\n",
        "preds_test = model(inputs)\n",
        "loss = loss_fn(preds_test, targets)\n",
        "print(loss)\n",
        "print(\"We can see that loss has been reduced. It can be reduced further by hyperparameter tuning, using better optimization techniques and loss functions\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcsJrim-GBfe",
        "outputId": "54dcb18a-0c8a-43a9-8888-c68b53aa077d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(11890.3477, grad_fn=<DivBackward0>)\n",
            "We can see that loss has been reduced. It can be reduced further by hyperparameter tuning, using better optimization techniques and loss functions\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hk6AP8BLGePS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear Regression using Pytorch built-in functions"
      ],
      "metadata": {
        "id": "O79fD283H-lx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "ILHKDrorIQy3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining inputs and targets\n",
        "\n",
        "inputs_np = np.array([[256, 710], \n",
        "                    [81, 101], \n",
        "                    [119, 133], \n",
        "                    [222, 137],\n",
        "                    [352, 437], \n",
        "                    [103, 119]], dtype='float32')\n",
        "\n",
        "targets_np = np.array([[256, 710], \n",
        "                    [81, 101], \n",
        "                    [119, 133], \n",
        "                    [222, 137],\n",
        "                    [245, 145], \n",
        "                    [103, 119]], dtype='float32')\n",
        "\n",
        "inputs = torch.from_numpy(inputs_np)\n",
        "targets = torch.from_numpy(targets_np)"
      ],
      "metadata": {
        "id": "cRB5O38pIiRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' Importing Two modules from torch.utils.data namely, TensorDataset and DataLoader\n",
        "    The TensorDataset function takes-in inputs and targets and gives them as a tuple \n",
        "    The DataLoader function is used for shuffling of the data and sorting the data into different batches(used when large data is there)\n",
        "'''\n",
        "from torch.utils.data import TensorDataset \n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "## Defining the dataset as a tuple\n",
        "\n",
        "train_ds =  TensorDataset(inputs, targets)\n",
        "\n",
        "batch_size = 2\n",
        "train_dl = DataLoader(train_ds, batch_size, shuffle = True)\n",
        "\n",
        "# Visualize the first batch of the dataset\n",
        "for x, y in train_dl:\n",
        "  print(x)\n",
        "  print(y)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ez1CiWkI6-P",
        "outputId": "fc508e8d-00f6-4c69-d6fc-2c1e5986d743"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[352., 437.],\n",
            "        [119., 133.]])\n",
            "tensor([[245., 145.],\n",
            "        [119., 133.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "############### Define THE MODEL ##################\n",
        "\n",
        "model1 = nn.Linear(3,2)\n",
        "print(model.weight.shape)\n",
        "print(model.bias)\n",
        "print(list(model.parameters())) #### model.parameters contains all the parameter matrices(weights and biases) in the network (there can be more than one).\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jtj_wssaKlP2",
        "outputId": "fa3f657e-c7a8-4a8f-b870-00135dd351e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3])\n",
            "Parameter containing:\n",
            "tensor([0.2681, 0.1994], requires_grad=True)\n",
            "[Parameter containing:\n",
            "tensor([[-0.5609,  0.3026,  0.4198],\n",
            "        [-0.1237, -0.3806,  0.4897]], requires_grad=True), Parameter containing:\n",
            "tensor([0.2681, 0.1994], requires_grad=True)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model1(inputs)\n",
        "preds"
      ],
      "metadata": {
        "id": "amQOuqdYLyAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### Defining loss function\n",
        "\n",
        "import torch.nn.functional as F\n",
        "\n",
        "mse_loss = F.mse_loss\n",
        "\n",
        "\n",
        "#### Define Optimizer\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "opt = optim.SGD(model.parameters(), lr = 1e-5)\n",
        "\n"
      ],
      "metadata": {
        "id": "ouFQxpZsMYVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Train the model\n",
        "def fit(num_epochs,model, mse_loss, opt, train_dl):\n",
        "  for epoch in range(num_epochs):\n",
        "    for xb, yb in train_dl:\n",
        "      pred = model(xb)\n",
        "      loss = mse_loss(pred, yb)\n",
        "      loss.backward()\n",
        "      \n",
        "      opt.step()\n",
        "      opt.zero_grad()\n"
      ],
      "metadata": {
        "id": "OOzhmv2XO2yl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Call the training function\n",
        "fit(100, model, mse_loss, opt, train_dl)\n",
        "\n",
        "### Test the trained model\n",
        "predictions = model(inputs)\n"
      ],
      "metadata": {
        "id": "svJej-7DQ1tu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xA16dWody54f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}